{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install --quiet pytorch-lightning>=1.4"
      ],
      "metadata": {
        "id": "6g1ZCAIYdOQW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5jqxWatBBLAl"
      },
      "outputs": [],
      "source": [
        "## Credits to https://uvadlc-notebooks.readthedocs.io/en/latest/tutorial_notebooks/tutorial12/Autoregressive_Image_Modeling.html\n",
        "\n",
        "import os\n",
        "import math\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "plt.set_cmap('cividis')\n",
        "%matplotlib inline\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data as data\n",
        "import torch.optim as optim\n",
        "\n",
        "import torchvision\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision import transforms\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "diIQbmlDZCDU"
      },
      "outputs": [],
      "source": [
        "DATASET_PATH = '../data/'\n",
        "\n",
        "pl.seed_everything(42)\n",
        "\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "\n",
        "device = torch.device('cpu') if not torch.cuda.is_available() else torch.device('cuda:0')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HLH1O_1Ja676"
      },
      "outputs": [],
      "source": [
        "def discretize(sample):\n",
        "    return (sample*255).to(torch.long)\n",
        "\n",
        "transform = transforms.Compose([transforms.ToTensor(), discretize])\n",
        "\n",
        "main_data = MNIST(root=DATASET_PATH, train=True, transform=transform, download=True)\n",
        "train_dataset = [x for x in main_data if x[1] == 7]\n",
        "pl.seed_everything(42)\n",
        "train_set, val_set = torch.utils.data.random_split(train_dataset, [int(0.8*len(train_dataset)), len(train_dataset)-int(0.8*len(train_dataset))])\n",
        "\n",
        "test_set = MNIST(root=DATASET_PATH, train=False, transform=transform, download=True)\n",
        "test_set = [x for x in test_set if x[1] == 7]\n",
        "\n",
        "train_loader = data.DataLoader(train_set, batch_size=128, shuffle=True, drop_last=True, pin_memory=True, num_workers=2)\n",
        "val_loader = data.DataLoader(val_set, batch_size=128, shuffle=False, drop_last=False, num_workers=2)\n",
        "test_loader = data.DataLoader(test_set, batch_size=128, shuffle=False, drop_last=False, num_workers=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-WksOVdWdCM7"
      },
      "outputs": [],
      "source": [
        "class MaskedConvolution(nn.Module):\n",
        "    def __init__(self, c_in, c_out, mask, **kwargs):\n",
        "        super().__init__()\n",
        "        kernel_size = (mask.shape[0], mask.shape[1])\n",
        "        dilation = 1 if 'dilation' not in kwargs else kwargs['dilation']\n",
        "        padding = tuple([dilation*(kernel_size[i]-1)//2 for i in range(2)])\n",
        "\n",
        "        self.conv = nn.Conv2d(c_in, c_out, kernel_size, padding=padding, **kwargs)\n",
        "\n",
        "        self.register_buffer('mask', mask[None, None])\n",
        "\n",
        "    def forward(self, x):\n",
        "        self.conv.weight.data *= self.mask\n",
        "        return self.conv(x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gCHvwQ39neig"
      },
      "outputs": [],
      "source": [
        "class VerticalStackConvolution(MaskedConvolution):\n",
        "    def __init__(self, c_in, c_out, kernel_size=3, mask_center=False, **kwargs):\n",
        "        mask = torch.ones(kernel_size, kernel_size)\n",
        "        mask[kernel_size//2+1:, :] = 0\n",
        "\n",
        "        if mask_center:\n",
        "            mask[kernel_size//2:, :] = 0\n",
        "\n",
        "        super().__init__(c_in, c_out, mask, **kwargs)\n",
        "\n",
        "class HorizontalStackConvolution(MaskedConvolution):\n",
        "    def __init__(self, c_in, c_out, kernel_size=3, mask_center=False, **kwargs):\n",
        "        mask = torch.ones(1, kernel_size)\n",
        "        mask[0, kernel_size//2+1:] = 0\n",
        "\n",
        "        if mask_center:\n",
        "            mask[0, kernel_size//2:] = 0\n",
        "\n",
        "        super().__init__(c_in, c_out, mask, **kwargs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F72_70mH8kak"
      },
      "outputs": [],
      "source": [
        "class GatedMaskedConv(nn.Module):\n",
        "\n",
        "    def __init__(self, c_in, **kwargs):\n",
        "        \"\"\"\n",
        "        Gated Convolution block implemented the computation graph shown above.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.conv_vert = VerticalStackConvolution(c_in, c_out=2*c_in, **kwargs)\n",
        "        self.conv_horiz = HorizontalStackConvolution(c_in, c_out=2*c_in, **kwargs)\n",
        "        self.conv_vert_to_horiz = nn.Conv2d(2*c_in, 2*c_in, kernel_size=1, padding=0)\n",
        "        self.conv_horiz_1x1 = nn.Conv2d(c_in, c_in, kernel_size=1, padding=0)\n",
        "\n",
        "    def forward(self, v_stack, h_stack):\n",
        "        # Vertical stack (left)\n",
        "        v_stack_feat = self.conv_vert(v_stack)\n",
        "        v_val, v_gate = v_stack_feat.chunk(2, dim=1)\n",
        "        v_stack_out = torch.tanh(v_val) * torch.sigmoid(v_gate)\n",
        "\n",
        "        # Horizontal stack (right)\n",
        "        h_stack_feat = self.conv_horiz(h_stack)\n",
        "        h_stack_feat = h_stack_feat + self.conv_vert_to_horiz(v_stack_feat)\n",
        "        h_val, h_gate = h_stack_feat.chunk(2, dim=1)\n",
        "        h_stack_feat = torch.tanh(h_val) * torch.sigmoid(h_gate)\n",
        "        h_stack_out = self.conv_horiz_1x1(h_stack_feat)\n",
        "        h_stack_out = h_stack_out + h_stack\n",
        "\n",
        "        return v_stack_out, h_stack_out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KXRaQ6E68cWR"
      },
      "outputs": [],
      "source": [
        "class PixelCNN(pl.LightningModule):\n",
        "\n",
        "    def __init__(self, c_in, c_hidden):\n",
        "        super().__init__()\n",
        "        self.save_hyperparameters()\n",
        "        self.pred_list = []\n",
        "        self.prob_list = torch.zeros((28*28, 256))\n",
        "        self.nll_list = []\n",
        "        self.conv_vstack = VerticalStackConvolution(c_in, c_hidden, mask_center=True)\n",
        "        self.conv_hstack = HorizontalStackConvolution(c_in, c_hidden, mask_center=True)\n",
        "        self.conv_layers = nn.ModuleList([\n",
        "            GatedMaskedConv(c_hidden),\n",
        "            GatedMaskedConv(c_hidden, dilation=2),\n",
        "            GatedMaskedConv(c_hidden),\n",
        "            GatedMaskedConv(c_hidden, dilation=4),\n",
        "            GatedMaskedConv(c_hidden),\n",
        "            GatedMaskedConv(c_hidden, dilation=2),\n",
        "            GatedMaskedConv(c_hidden)\n",
        "        ])\n",
        "        self.conv_out = nn.Conv2d(c_hidden, c_in * 256, kernel_size=1, padding=0)\n",
        "\n",
        "        self.example_input_array = train_set[0][0][None]\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = (x.float() / 255.0) * 2 - 1\n",
        "        v_stack = self.conv_vstack(x)\n",
        "        h_stack = self.conv_hstack(x)\n",
        "        for layer in self.conv_layers:\n",
        "            v_stack, h_stack = layer(v_stack, h_stack)\n",
        "        out = self.conv_out(F.elu(h_stack))\n",
        "\n",
        "        out = out.reshape(out.shape[0], 256, out.shape[1]//256, out.shape[2], out.shape[3])\n",
        "        return out\n",
        "\n",
        "    def calc_likelihood(self, x):\n",
        "        pred = self.forward(x)\n",
        "        nll = F.cross_entropy(pred, x, reduction='none')\n",
        "        bpd = nll.mean(dim=[1,2,3]) * np.log2(np.exp(1))\n",
        "        return bpd.mean()\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def sample(self, img_shape, img=None):\n",
        "\n",
        "        counter = 0\n",
        "        if img is None:\n",
        "            img = torch.zeros(img_shape, dtype=torch.long).to(device) - 1\n",
        "        for h in tqdm(range(img_shape[2]), leave=False):\n",
        "            for w in range(img_shape[3]):\n",
        "                for c in range(img_shape[1]):\n",
        "                    if (img[:,c,h,w] != -1).all().item():\n",
        "                        continue\n",
        "\n",
        "                    pred = self.forward(img[:,:,:h+1,:])\n",
        "                    self.pred_list.append(pred)\n",
        "                    probs = F.softmax(pred[:,:,c,h,w], dim=-1)\n",
        "                    self.prob_list[counter] = probs\n",
        "                    counter += 1\n",
        "                    img[:,c,h,w] = torch.multinomial(probs, num_samples=1).squeeze(dim=-1)\n",
        "        return self.pred_list, self.prob_list, img\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = optim.Adam(self.parameters(), lr=1e-3)\n",
        "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=5, verbose=False)\n",
        "        return [optimizer], [{'scheduler': scheduler, 'monitor':'val_bpd'}]\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        loss = self.calc_likelihood(batch[0])\n",
        "        self.log('train_bpd', loss)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        loss = self.calc_likelihood(batch[0])\n",
        "        self.log('val_bpd', loss)\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        loss = self.calc_likelihood(batch[0])\n",
        "        self.log('test_bpd', loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6HUjs8uZOfNG"
      },
      "source": [
        "# Denoising Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mw39xXupVE66"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "import time\n",
        "from torchvision.utils import save_image\n",
        "\n",
        "class test_model_1():\n",
        "\n",
        "    def __init__(self):\n",
        "        torch.manual_seed(142)\n",
        "        self.ARmodel = PixelCNN(c_in=1, c_hidden=64).to(device)\n",
        "        self.ARmodel.load_state_dict(torch.load('saved_model.pt'))\n",
        "        self.trainable_params = []\n",
        "        self.automatic_optimization = False\n",
        "\n",
        "    def forward(self, curr_est, x):\n",
        "        log_loss = self.compute_likelihood(curr_est)\n",
        "        MSEloss = nn.MSELoss()\n",
        "        mse_loss = ((curr_est-x)**2).mean()\n",
        "        return mse_loss, log_loss\n",
        "\n",
        "    def compute_likelihood(self, x):\n",
        "        torch.manual_seed(142)\n",
        "        x = x.unsqueeze(0)\n",
        "        logits = self.ARmodel(x).squeeze()\n",
        "        logits = logits.permute((1,2,0))\n",
        "        exp_logits = torch.exp(logits)\n",
        "        probs = exp_logits/torch.sum(exp_logits, dim=2, keepdim=True)\n",
        "        log_l = 0.0\n",
        "        x = x.squeeze()\n",
        "        log_l = -1.0*torch.log(self.interpolate(probs, x))\n",
        "        return log_l\n",
        "\n",
        "    def training_loop(self, x, sigma, max_iterations=10000, lr=0.01, sigma_w=30.0):\n",
        "\n",
        "        '''\n",
        "        The main training loop function. Choose whichever curr_est you wish to have\n",
        "        and comment out the rest.\n",
        "        '''\n",
        "        curr_est = x.detach().clone().requires_grad_() # The noisy image as input\n",
        "        #curr_est = torch.zeros_like(x).requires_grad_() # Blank image as input\n",
        "        #curr_est = torch.randn(x.shape).requires_grad_() # Random noise as input\n",
        "        log_loss_list = []\n",
        "        total_loss_list = []\n",
        "        mse_loss_list = []\n",
        "        optimizer = torch.optim.Adam([curr_est], lr=lr)\n",
        "        for i in range(max_iterations):\n",
        "\n",
        "            if i%500 == 0 and i!=0:\n",
        "                self.save_curr_est(i, curr_est)\n",
        "            start = time.time()\n",
        "            optimizer.zero_grad()\n",
        "            mse_loss, log_loss = self.forward(curr_est, x)\n",
        "            total_loss = mse_loss/(sigma_w*sigma*sigma) + log_loss      ### The main loss equation\n",
        "            total_loss.backward()\n",
        "            optimizer.step()\n",
        "            end = time.time()\n",
        "            print('[INFO] epoch ' + str(i) + ': MSEloss = ' + str(mse_loss.item()) + ' | Log loss = ' + str(log_loss.item()))\n",
        "            print(end-start)\n",
        "            log_loss_list.append(log_loss.item())\n",
        "            mse_loss_list.append(mse_loss.item())\n",
        "            total_loss_list.append(total_loss.item())\n",
        "        return curr_est, log_loss_list, mse_loss_list, total_loss_list\n",
        "\n",
        "    def print_trainable_params(self):\n",
        "        print(\"Trainable Parameters:\")\n",
        "        for name, param in self.named_parameters():\n",
        "            if param.requires_grad:\n",
        "                print(name)\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        pass\n",
        "\n",
        "    def save_curr_est(self, epoch, curr_est):\n",
        "        print('Saving image at epoch: ' + str(epoch))\n",
        "        save_image(curr_est, '/content/epoch'+str(epoch)+'.png')\n",
        "\n",
        "    def interpolate(self, dist, x):\n",
        "        x_ = x.reshape((28*28,))\n",
        "        x_ = torch.clamp(x_, 0.0001, 255-0.0001)\n",
        "        dist_ = dist.reshape((28*28, 256))\n",
        "        ceil_q = torch.ceil(x_).detach().long()\n",
        "        alpha = ceil_q - x_\n",
        "        floor_q = torch.floor(x_).detach().long()\n",
        "\n",
        "\n",
        "        q_floor = dist_[torch.arange(x_.shape[0]), floor_q]\n",
        "        q_ceil = dist_[torch.arange(x_.shape[0]), ceil_q]\n",
        "        q_y = alpha * q_floor + (1 - alpha) * q_ceil\n",
        "        return q_y.mean()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iFCGFp92RQmt"
      },
      "outputs": [],
      "source": [
        "denoising_model = test_model_1()\n",
        "training_set = np.zeros((len(test_set), 28, 28))\n",
        "for i in range(len(test_set)):\n",
        "    training_set[i] = torch.squeeze(test_set[i][0])\n",
        "pl.seed_everything(142)\n",
        "\n",
        "training_set = torch.from_numpy(training_set).float()\n",
        "\n",
        "i = 1 #1, 10, 100 the images chosen for testing.\n",
        "sigma = 50.0   ### Standard deviation of noise added\n",
        "\n",
        "x = training_set[i] + torch.randn((28,28))*sigma\n",
        "x = np.clip(x, 0.0, 255.0)     ### Make sure that the pixel values are within bounds\n",
        "\n",
        "plt.imshow(x.squeeze(), cmap='gray')\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "plt.imshow(training_set[i].squeeze(), cmap='gray')\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "denoising_model.compute_likelihood(training_set[i].unsqueeze(0)), denoising_model.compute_likelihood(x.unsqueeze(0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0cHffUlW_oEv"
      },
      "outputs": [],
      "source": [
        "denoising_model = test_model_1()\n",
        "x = x.to(device)\n",
        "output = denoising_model.training_loop(x.unsqueeze(0), sigma, 5, 0.1, sigma_w=30.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RTX753Sn9toc"
      },
      "outputs": [],
      "source": [
        "out = output[0].cpu().detach().numpy()\n",
        "out[0] = np.clip(out[0], 0, 255)\n",
        "plt.imshow(out[0], vmin=0, vmax=255, cmap='gray')\n",
        "plt.show()\n",
        "plt.imshow(training_set[i], vmin=0, vmax=255, cmap='gray')\n",
        "plt.show()\n",
        "plt.imshow(x, vmin=0, vmax=255, cmap='gray')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Iy-uC_qQaVm"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(1,3, figsize=(15, 5))\n",
        "\n",
        "ax[0].plot(output[1])\n",
        "ax[0].set_title('log loss')\n",
        "ax[1].plot(output[2])\n",
        "ax[1].set_title('MSE loss')\n",
        "ax[2].plot(output[3])\n",
        "ax[2].set_title('total loss')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OpM3j0VH3r1M"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "65xvuJuDH9Ho"
      },
      "outputs": [],
      "source": [
        "mse_clean = ((training_set[i]-out[0])**2).mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qy6UE6jF22c9"
      },
      "outputs": [],
      "source": [
        "### PSNR calculation\n",
        "\n",
        "psnr = 10 * torch.log10((255*255) / mse_clean)\n",
        "print(psnr.item())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "soP4g0g3iTnz"
      },
      "outputs": [],
      "source": [
        "### SSIM calculation\n",
        "\n",
        "from skimage.metrics import structural_similarity as compare_ssim\n",
        "\n",
        "A = training_set[i].cpu().numpy()\n",
        "B = out[0]\n",
        "\n",
        "(score, diff) = compare_ssim(A, B, full=True)\n",
        "print(score)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2Pfb1Hsk3u7T"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}